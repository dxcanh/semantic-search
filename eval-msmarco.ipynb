{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-14T12:30:44.375874Z",
     "iopub.status.busy": "2023-12-14T12:30:44.375586Z",
     "iopub.status.idle": "2023-12-14T12:30:59.671598Z",
     "shell.execute_reply": "2023-12-14T12:30:59.670519Z",
     "shell.execute_reply.started": "2023-12-14T12:30:44.375848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=c1f6d46f4ba40092f9f56fd162ffc4c12281c6c41e178263d31c7474ab9ca82a\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:29:11.809221Z",
     "iopub.status.busy": "2023-12-14T13:29:11.808549Z",
     "iopub.status.idle": "2023-12-14T13:29:11.864011Z",
     "shell.execute_reply": "2023-12-14T13:29:11.863032Z",
     "shell.execute_reply.started": "2023-12-14T13:29:11.809183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "from sentence_transformers.util import cos_sim, dot_score\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Set, Callable\n",
    "import heapq\n",
    "import pickle\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InformationRetrievalEvaluator(SentenceEvaluator):\n",
    "    \"\"\"\n",
    "    This class evaluates an Information Retrieval (IR) setting.\n",
    "\n",
    "    Given a set of queries and a large corpus set. It will retrieve for each query the top-k most similar document. It measures\n",
    "    Mean Reciprocal Rank (MRR), Recall@k, and Normalized Discounted Cumulative Gain (NDCG)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 queries: Dict[str, str],  #qid => query\n",
    "                 corpus: Dict[str, str],  #cid => doc\n",
    "                 relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n",
    "                 corpus_chunk_size: int = 50000,\n",
    "                 mrr_at_k: List[int] = [10],\n",
    "                 ndcg_at_k: List[int] = [10],\n",
    "                 accuracy_at_k: List[int] = [1, 3, 5, 10],\n",
    "                 precision_recall_at_k: List[int] = [1, 3, 5, 10],\n",
    "                 map_at_k: List[int] = [100],\n",
    "                 show_progress_bar: bool = False,\n",
    "                 batch_size: int = 32,\n",
    "                 name: str = '',\n",
    "                 write_csv: bool = True,\n",
    "                 score_functions: List[Callable[[Tensor, Tensor], Tensor] ] = {'cos_sim': cos_sim, 'dot_score': dot_score},       #Score function, higher=more similar\n",
    "                 main_score_function: str = None\n",
    "                 ):\n",
    "\n",
    "        self.queries_ids = []\n",
    "        for qid in queries:\n",
    "            if qid in relevant_docs and len(relevant_docs[qid]) > 0:\n",
    "                self.queries_ids.append(qid)\n",
    "\n",
    "        self.queries = [queries[qid] for qid in self.queries_ids]\n",
    "\n",
    "        self.corpus_ids = list(corpus.keys())\n",
    "        self.corpus = [corpus[cid] for cid in self.corpus_ids]\n",
    "\n",
    "        self.relevant_docs = relevant_docs\n",
    "        self.corpus_chunk_size = corpus_chunk_size\n",
    "        self.mrr_at_k = mrr_at_k\n",
    "        self.ndcg_at_k = ndcg_at_k\n",
    "        self.accuracy_at_k = accuracy_at_k\n",
    "        self.precision_recall_at_k = precision_recall_at_k\n",
    "        self.map_at_k = map_at_k\n",
    "\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "        self.write_csv = write_csv\n",
    "        self.score_functions = score_functions\n",
    "        self.score_function_names = sorted(list(self.score_functions.keys()))\n",
    "        self.main_score_function = main_score_function\n",
    "\n",
    "        if name:\n",
    "            name = \"_\" + name\n",
    "\n",
    "        self.csv_file: str = \"Information-Retrieval_evaluation\" + name + \"_results.csv\"\n",
    "        self.csv_headers = [\"epoch\", \"steps\"]\n",
    "\n",
    "        for score_name in self.score_function_names:\n",
    "            for k in accuracy_at_k:\n",
    "                self.csv_headers.append(\"{}-Accuracy@{}\".format(score_name, k))\n",
    "\n",
    "            for k in precision_recall_at_k:\n",
    "                self.csv_headers.append(\"{}-Precision@{}\".format(score_name, k))\n",
    "                self.csv_headers.append(\"{}-Recall@{}\".format(score_name, k))\n",
    "\n",
    "            for k in mrr_at_k:\n",
    "                self.csv_headers.append(\"{}-MRR@{}\".format(score_name, k))\n",
    "\n",
    "            for k in ndcg_at_k:\n",
    "                self.csv_headers.append(\"{}-NDCG@{}\".format(score_name, k))\n",
    "\n",
    "            for k in map_at_k:\n",
    "                self.csv_headers.append(\"{}-MAP@{}\".format(score_name, k))\n",
    "\n",
    "    def __call__(self, model,  epoch: int = -1, steps: int = -1, *args, **kwargs) -> float:\n",
    "        if epoch != -1:\n",
    "            out_txt = \" after epoch {}:\".format(epoch) if steps == -1 else \" in epoch {} after {} steps:\".format(epoch, steps)\n",
    "        else:\n",
    "            out_txt = \":\"\n",
    "\n",
    "        logger.info(\"Information Retrieval Evaluation on \" + self.name + \" dataset\" + out_txt)\n",
    "\n",
    "        scores = self.compute_metrices(model, *args, **kwargs)\n",
    "        # Write results to disc\n",
    "        if  self.write_csv:\n",
    "            csv_path = os.path.join('./', self.csv_file)\n",
    "            if not os.path.isfile(csv_path):\n",
    "                fOut = open(csv_path, mode=\"w\", encoding=\"utf-8\")\n",
    "                fOut.write(\",\".join(self.csv_headers))\n",
    "                fOut.write(\"\\n\")\n",
    "\n",
    "            else:\n",
    "                fOut = open(csv_path, mode=\"a\", encoding=\"utf-8\")\n",
    "\n",
    "            output_data = [epoch, steps]\n",
    "            for name in self.score_function_names:\n",
    "                for k in self.accuracy_at_k:\n",
    "                    output_data.append(scores[name]['accuracy@k'][k])\n",
    "\n",
    "                for k in self.precision_recall_at_k:\n",
    "                    output_data.append(scores[name]['precision@k'][k])\n",
    "                    output_data.append(scores[name]['recall@k'][k])\n",
    "\n",
    "                for k in self.mrr_at_k:\n",
    "                    output_data.append(scores[name]['mrr@k'][k])\n",
    "\n",
    "                for k in self.ndcg_at_k:\n",
    "                    output_data.append(scores[name]['ndcg@k'][k])\n",
    "\n",
    "                for k in self.map_at_k:\n",
    "                    output_data.append(scores[name]['map@k'][k])\n",
    "\n",
    "            fOut.write(\",\".join(map(str, output_data)))\n",
    "            fOut.write(\"\\n\")\n",
    "            fOut.close()\n",
    "\n",
    "        if self.main_score_function is None:\n",
    "            return max([scores[name]['map@k'][max(self.map_at_k)] for name in self.score_function_names])\n",
    "        else:\n",
    "            return scores[self.main_score_function]['map@k'][max(self.map_at_k)]\n",
    "\n",
    "    def compute_metrices(self, model, corpus_model = None, corpus_embeddings: Tensor = None) -> Dict[str, float]:\n",
    "        if corpus_model is None:\n",
    "            corpus_model = model\n",
    "\n",
    "        max_k = max(max(self.mrr_at_k), max(self.ndcg_at_k), max(self.accuracy_at_k), max(self.precision_recall_at_k), max(self.map_at_k))\n",
    "\n",
    "        # Compute embedding for the queries\n",
    "        query_embeddings = model.encode(self.queries, show_progress_bar=self.show_progress_bar, batch_size=self.batch_size, convert_to_tensor=True)\n",
    "\n",
    "        queries_result_list = {}\n",
    "        for name in self.score_functions:\n",
    "            queries_result_list[name] = [[] for _ in range(len(query_embeddings))]\n",
    "\n",
    "        #Iterate over chunks of the corpus\n",
    "        for corpus_start_idx in trange(0, len(self.corpus), self.corpus_chunk_size, desc='Corpus Chunks', disable=not self.show_progress_bar):\n",
    "            corpus_end_idx = min(corpus_start_idx + self.corpus_chunk_size, len(self.corpus))\n",
    "\n",
    "            #Encode chunk of corpus\n",
    "            if corpus_embeddings is None:\n",
    "                sub_corpus_embeddings = corpus_model.encode(self.corpus[corpus_start_idx:corpus_end_idx], show_progress_bar=False, batch_size=self.batch_size, convert_to_tensor=True)\n",
    "            else:\n",
    "                sub_corpus_embeddings = corpus_embeddings[corpus_start_idx:corpus_end_idx]\n",
    "\n",
    "            #Compute cosine similarites\n",
    "            for name, score_function in self.score_functions.items():\n",
    "                pair_scores = score_function(query_embeddings, sub_corpus_embeddings)\n",
    "\n",
    "                #Get top-k values\n",
    "                pair_scores_top_k_values, pair_scores_top_k_idx = torch.topk(pair_scores, min(max_k, len(pair_scores[0])), dim=1, largest=True, sorted=False)\n",
    "                pair_scores_top_k_values = pair_scores_top_k_values.cpu().tolist()\n",
    "                pair_scores_top_k_idx = pair_scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "                for query_itr in range(len(query_embeddings)):\n",
    "                    for sub_corpus_id, score in zip(pair_scores_top_k_idx[query_itr], pair_scores_top_k_values[query_itr]):\n",
    "                        corpus_id = self.corpus_ids[corpus_start_idx+sub_corpus_id]\n",
    "                        if len(queries_result_list[name][query_itr]) < max_k:\n",
    "                            heapq.heappush(queries_result_list[name][query_itr], (score, corpus_id))  # heaqp tracks the quantity of the first element in the tuple\n",
    "                        else:\n",
    "                            heapq.heappushpop(queries_result_list[name][query_itr], (score, corpus_id))\n",
    "\n",
    "        for name in queries_result_list:\n",
    "            for query_itr in range(len(queries_result_list[name])):\n",
    "                for doc_itr in range(len(queries_result_list[name][query_itr])):\n",
    "                    score, corpus_id = queries_result_list[name][query_itr][doc_itr]\n",
    "                    queries_result_list[name][query_itr][doc_itr] = {'corpus_id': corpus_id, 'score': score}\n",
    "\n",
    "        logger.info(\"Queries: {}\".format(len(self.queries)))\n",
    "        logger.info(\"Corpus: {}\\n\".format(len(self.corpus)))\n",
    "        logger.info(\"Saving queries_result_list.pkl\")\n",
    "        with open('queries_result_list.pkl', 'wb') as f:\n",
    "            pickle.dump(queries_result_list, f)\n",
    "        #Compute scores\n",
    "        logger.info(\"Computing scores...\")\n",
    "        scores = {name: self.compute_metrics(queries_result_list[name]) for name in self.score_functions}\n",
    "        \n",
    "        #Output\n",
    "        for name in self.score_function_names:\n",
    "            logger.info(\"Score-Function: {}\".format(name))\n",
    "            self.output_scores(scores[name])\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def compute_metrics(self, queries_result_list: List[object]):\n",
    "        # Init score computation values\n",
    "        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n",
    "        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n",
    "        MRR = {k: 0 for k in self.mrr_at_k}\n",
    "        ndcg = {k: [] for k in self.ndcg_at_k}\n",
    "        AveP_at_k = {k: [] for k in self.map_at_k}\n",
    "\n",
    "        # Compute scores on results\n",
    "        for query_itr in range(len(queries_result_list)):\n",
    "            query_id = self.queries_ids[query_itr]\n",
    "\n",
    "            # Sort scores\n",
    "            top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n",
    "            query_relevant_docs = self.relevant_docs[query_id]\n",
    "\n",
    "            # Accuracy@k - We count the result correct, if at least one relevant doc is across the top-k documents\n",
    "            for k_val in self.accuracy_at_k:\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_hits_at_k[k_val] += 1\n",
    "                        break\n",
    "\n",
    "            # Precision and Recall@k\n",
    "            for k_val in self.precision_recall_at_k:\n",
    "                num_correct = 0\n",
    "                for hit in top_hits[0:k_val]:\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_correct += 1\n",
    "\n",
    "                precisions_at_k[k_val].append(num_correct / k_val)\n",
    "                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n",
    "\n",
    "            # MRR@k\n",
    "            for k_val in self.mrr_at_k:\n",
    "                for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        MRR[k_val] += 1.0 / (rank + 1)\n",
    "                        break\n",
    "\n",
    "            # NDCG@k\n",
    "            for k_val in self.ndcg_at_k:\n",
    "                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n",
    "                true_relevances = [1] * len(query_relevant_docs)\n",
    "\n",
    "                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n",
    "                ndcg[k_val].append(ndcg_value)\n",
    "\n",
    "            # MAP@k\n",
    "            for k_val in self.map_at_k:\n",
    "                num_correct = 0\n",
    "                sum_precisions = 0\n",
    "\n",
    "                for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "                    if hit['corpus_id'] in query_relevant_docs:\n",
    "                        num_correct += 1\n",
    "                        sum_precisions += num_correct / (rank + 1)\n",
    "\n",
    "                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n",
    "                AveP_at_k[k_val].append(avg_precision)\n",
    "\n",
    "        # Compute averages\n",
    "        for k in num_hits_at_k:\n",
    "            num_hits_at_k[k] /= len(self.queries)\n",
    "\n",
    "        for k in precisions_at_k:\n",
    "            precisions_at_k[k] = np.mean(precisions_at_k[k])\n",
    "\n",
    "        for k in recall_at_k:\n",
    "            recall_at_k[k] = np.mean(recall_at_k[k])\n",
    "\n",
    "        for k in ndcg:\n",
    "            ndcg[k] = np.mean(ndcg[k])\n",
    "\n",
    "        for k in MRR:\n",
    "            MRR[k] /= len(self.queries)\n",
    "\n",
    "        for k in AveP_at_k:\n",
    "            AveP_at_k[k] = np.mean(AveP_at_k[k])\n",
    "\n",
    "\n",
    "        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n",
    "\n",
    "\n",
    "    def output_scores(self, scores):\n",
    "        for k in scores['accuracy@k']:\n",
    "            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores['accuracy@k'][k]*100))\n",
    "\n",
    "        for k in scores['precision@k']:\n",
    "            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores['precision@k'][k]*100))\n",
    "\n",
    "        for k in scores['recall@k']:\n",
    "            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores['recall@k'][k]*100))\n",
    "\n",
    "        for k in scores['mrr@k']:\n",
    "            logger.info(\"MRR@{}: {:.4f}\".format(k, scores['mrr@k'][k]))\n",
    "\n",
    "        for k in scores['ndcg@k']:\n",
    "            logger.info(\"NDCG@{}: {:.4f}\".format(k, scores['ndcg@k'][k]))\n",
    "\n",
    "        for k in scores['map@k']:\n",
    "            logger.info(\"MAP@{}: {:.4f}\".format(k, scores['map@k'][k]))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_dcg_at_k(relevances, k):\n",
    "        dcg = 0\n",
    "        for i in range(min(len(relevances), k)):\n",
    "            dcg += relevances[i] / np.log2(i + 2)  #+2 as we start our idx at 0\n",
    "        return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:31:42.717711Z",
     "iopub.status.busy": "2023-12-14T12:31:42.717011Z",
     "iopub.status.idle": "2023-12-14T12:31:42.721894Z",
     "shell.execute_reply": "2023-12-14T12:31:42.720920Z",
     "shell.execute_reply.started": "2023-12-14T12:31:42.717676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "import logging\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:31:58.913500Z",
     "iopub.status.busy": "2023-12-14T12:31:58.912607Z",
     "iopub.status.idle": "2023-12-14T12:31:58.917395Z",
     "shell.execute_reply": "2023-12-14T12:31:58.916534Z",
     "shell.execute_reply.started": "2023-12-14T12:31:58.913463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:32:00.324639Z",
     "iopub.status.busy": "2023-12-14T12:32:00.324262Z",
     "iopub.status.idle": "2023-12-14T12:32:11.059816Z",
     "shell.execute_reply": "2023-12-14T12:32:11.059008Z",
     "shell.execute_reply.started": "2023-12-14T12:32:00.324608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:33:03.589596Z",
     "iopub.status.busy": "2023-12-14T12:33:03.589231Z",
     "iopub.status.idle": "2023-12-14T12:33:05.817678Z",
     "shell.execute_reply": "2023-12-14T12:33:05.816883Z",
     "shell.execute_reply.started": "2023-12-14T12:33:03.589567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dev_qrels = pickle.load(open('E:\\Python\\DL\\semantic-search\\msmarco-data\\dev_qrels_first_10k_with_bm25_top1000.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:33:15.481249Z",
     "iopub.status.busy": "2023-12-14T12:33:15.480885Z",
     "iopub.status.idle": "2023-12-14T12:33:15.486707Z",
     "shell.execute_reply": "2023-12-14T12:33:15.485768Z",
     "shell.execute_reply.started": "2023-12-14T12:33:15.481219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "corpus = {}             #Our corpus pid => passage\n",
    "queries = {}        #Our dev queries. qid => query\n",
    "dev_rel_docs = {}       #Mapping qid => set with relevant pids\n",
    "needed_pids = set()     #Passage IDs we need\n",
    "needed_qids = set()     #Query IDs we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:33:55.251983Z",
     "iopub.status.busy": "2023-12-14T12:33:55.251203Z",
     "iopub.status.idle": "2023-12-14T12:33:56.552953Z",
     "shell.execute_reply": "2023-12-14T12:33:56.552124Z",
     "shell.execute_reply.started": "2023-12-14T12:33:55.251950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dev_queries_file = 'E:\\Python\\DL\\semantic-search\\queries\\queries.dev.tsv'\n",
    "train_queries_file = 'E:\\Python\\DL\\semantic-search\\queries\\queries.train.tsv'\n",
    "eval_queries_file = 'E:\\Python\\DL\\semantic-search\\queries\\queries.eval.tsv'\n",
    "with open(dev_queries_file, encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        queries[int(qid)] = query.strip()\n",
    "\n",
    "with open(train_queries_file, encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        queries[int(qid)] = query.strip()\n",
    "with open(eval_queries_file, encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        qid, query = line.strip().split(\"\\t\")\n",
    "        queries[int(qid)] = query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:34:18.798418Z",
     "iopub.status.busy": "2023-12-14T12:34:18.798068Z",
     "iopub.status.idle": "2023-12-14T12:34:22.936661Z",
     "shell.execute_reply": "2023-12-14T12:34:22.935663Z",
     "shell.execute_reply.started": "2023-12-14T12:34:18.798392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read passages\n",
    "with open('E:\\Python\\DL\\semantic-search\\msmarco-data\\collection_in_use.tsv', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        pid, passage = line.strip().split(\"\\t\")\n",
    "        passage = passage\n",
    "        corpus[int(pid)] = passage.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:34:25.650071Z",
     "iopub.status.busy": "2023-12-14T12:34:25.649679Z",
     "iopub.status.idle": "2023-12-14T12:34:25.664398Z",
     "shell.execute_reply": "2023-12-14T12:34:25.663249Z",
     "shell.execute_reply.started": "2023-12-14T12:34:25.650043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dev_queries = {}\n",
    "for x in dev_qrels:\n",
    "    dev_queries[x['qid']] = queries[x['qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T12:34:32.447919Z",
     "iopub.status.busy": "2023-12-14T12:34:32.447542Z",
     "iopub.status.idle": "2023-12-14T12:34:32.474440Z",
     "shell.execute_reply": "2023-12-14T12:34:32.473491Z",
     "shell.execute_reply.started": "2023-12-14T12:34:32.447889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for x in dev_qrels:\n",
    "    qid,pid = x['qid'],x['pid']\n",
    "    if qid not in dev_queries:\n",
    "            continue\n",
    "    if qid not in dev_rel_docs:\n",
    "        dev_rel_docs[qid] = set()\n",
    "    dev_rel_docs[qid].add(pid)\n",
    "    needed_pids.add(pid)\n",
    "    needed_qids.add(qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:15:58.547566Z",
     "iopub.status.busy": "2023-12-14T13:15:58.546711Z",
     "iopub.status.idle": "2023-12-14T13:26:06.339910Z",
     "shell.execute_reply": "2023-12-14T13:26:06.338878Z",
     "shell.execute_reply.started": "2023-12-14T13:15:58.547532Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f427d1847a420184c8724f22a5d18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "ir_evaluator = InformationRetrievalEvaluator(dev_queries, corpus, dev_rel_docs,\n",
    "                                                        show_progress_bar=True,\n",
    "                                                        corpus_chunk_size=100000,\n",
    "                                                        precision_recall_at_k=[10, 100],\n",
    "                                                        name=\"msmarco dev\",\n",
    "                                                        write_csv = True)\n",
    "\n",
    "ir_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:26:56.414199Z",
     "iopub.status.busy": "2023-12-14T13:26:56.413817Z",
     "iopub.status.idle": "2023-12-14T13:26:56.419767Z",
     "shell.execute_reply": "2023-12-14T13:26:56.418582Z",
     "shell.execute_reply.started": "2023-12-14T13:26:56.414172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "res = pickle.load(open('/kaggle/working/scores.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:26:57.385674Z",
     "iopub.status.busy": "2023-12-14T13:26:57.384708Z",
     "iopub.status.idle": "2023-12-14T13:26:57.393742Z",
     "shell.execute_reply": "2023-12-14T13:26:57.392609Z",
     "shell.execute_reply.started": "2023-12-14T13:26:57.385631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cos_sim': {'accuracy@k': {1: 0.5044600692622521,\n",
       "   3: 0.7041662294049743,\n",
       "   5: 0.7717493965788645,\n",
       "   10: 0.8480428166649177},\n",
       "  'precision@k': {10: 0.08751180606569421, 100: 0.010086053101059922},\n",
       "  'recall@k': {10: 0.8408927134711582, 100: 0.9629919194039249},\n",
       "  'ndcg@k': {10: 0.6701923440702828},\n",
       "  'mrr@k': {10: 0.6188801686414217},\n",
       "  'map@k': {100: 0.6195057515472899}},\n",
       " 'dot_score': {'accuracy@k': {1: 0.5044600692622521,\n",
       "   3: 0.7041662294049743,\n",
       "   5: 0.7717493965788645,\n",
       "   10: 0.8480428166649177},\n",
       "  'precision@k': {10: 0.08751180606569421, 100: 0.010086053101059922},\n",
       "  'recall@k': {10: 0.8408927134711582, 100: 0.9629919194039249},\n",
       "  'ndcg@k': {10: 0.6701923440702828},\n",
       "  'mrr@k': {10: 0.6188801686414217},\n",
       "  'map@k': {100: 0.6195057515472899}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:27:42.236234Z",
     "iopub.status.busy": "2023-12-14T13:27:42.235382Z",
     "iopub.status.idle": "2023-12-14T13:27:42.559458Z",
     "shell.execute_reply": "2023-12-14T13:27:42.558692Z",
     "shell.execute_reply.started": "2023-12-14T13:27:42.236198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.read_csv('/kaggle/working/Information-Retrieval_evaluation_msmarco dev_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:33:32.631872Z",
     "iopub.status.busy": "2023-12-14T13:33:32.631477Z",
     "iopub.status.idle": "2023-12-14T13:33:32.651759Z",
     "shell.execute_reply": "2023-12-14T13:33:32.650852Z",
     "shell.execute_reply.started": "2023-12-14T13:33:32.631841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cos_sim-Accuracy@1</th>\n",
       "      <th>cos_sim-Accuracy@3</th>\n",
       "      <th>cos_sim-Accuracy@5</th>\n",
       "      <th>cos_sim-Accuracy@10</th>\n",
       "      <th>cos_sim-Precision@10</th>\n",
       "      <th>cos_sim-Recall@10</th>\n",
       "      <th>cos_sim-Precision@100</th>\n",
       "      <th>cos_sim-Recall@100</th>\n",
       "      <th>...</th>\n",
       "      <th>dot_score-Accuracy@3</th>\n",
       "      <th>dot_score-Accuracy@5</th>\n",
       "      <th>dot_score-Accuracy@10</th>\n",
       "      <th>dot_score-Precision@10</th>\n",
       "      <th>dot_score-Recall@10</th>\n",
       "      <th>dot_score-Precision@100</th>\n",
       "      <th>dot_score-Recall@100</th>\n",
       "      <th>dot_score-MRR@10</th>\n",
       "      <th>dot_score-NDCG@10</th>\n",
       "      <th>dot_score-MAP@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50446</td>\n",
       "      <td>0.704166</td>\n",
       "      <td>0.771749</td>\n",
       "      <td>0.848043</td>\n",
       "      <td>0.087512</td>\n",
       "      <td>0.840893</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.962992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704166</td>\n",
       "      <td>0.771749</td>\n",
       "      <td>0.848043</td>\n",
       "      <td>0.087512</td>\n",
       "      <td>0.840893</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.962992</td>\n",
       "      <td>0.61888</td>\n",
       "      <td>0.670192</td>\n",
       "      <td>0.619506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  steps  cos_sim-Accuracy@1  cos_sim-Accuracy@3  cos_sim-Accuracy@5  \\\n",
       "0     -1     -1             0.50446            0.704166            0.771749   \n",
       "\n",
       "   cos_sim-Accuracy@10  cos_sim-Precision@10  cos_sim-Recall@10  \\\n",
       "0             0.848043              0.087512           0.840893   \n",
       "\n",
       "   cos_sim-Precision@100  cos_sim-Recall@100  ...  dot_score-Accuracy@3  \\\n",
       "0               0.010086            0.962992  ...              0.704166   \n",
       "\n",
       "   dot_score-Accuracy@5  dot_score-Accuracy@10  dot_score-Precision@10  \\\n",
       "0              0.771749               0.848043                0.087512   \n",
       "\n",
       "   dot_score-Recall@10  dot_score-Precision@100  dot_score-Recall@100  \\\n",
       "0             0.840893                 0.010086              0.962992   \n",
       "\n",
       "   dot_score-MRR@10  dot_score-NDCG@10  dot_score-MAP@100  \n",
       "0           0.61888           0.670192           0.619506  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:30:31.398732Z",
     "iopub.status.busy": "2023-12-14T13:30:31.398002Z",
     "iopub.status.idle": "2023-12-14T13:30:32.415592Z",
     "shell.execute_reply": "2023-12-14T13:30:32.414775Z",
     "shell.execute_reply.started": "2023-12-14T13:30:31.398690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_scores = pickle.load(open('/kaggle/working/dot_scorequeries_result_list.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:33:51.516489Z",
     "iopub.status.busy": "2023-12-14T13:33:51.516103Z",
     "iopub.status.idle": "2023-12-14T13:33:51.522550Z",
     "shell.execute_reply": "2023-12-14T13:33:51.521613Z",
     "shell.execute_reply.started": "2023-12-14T13:33:51.516459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cos_sim', 'dot_score'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T13:34:23.387398Z",
     "iopub.status.busy": "2023-12-14T13:34:23.386493Z",
     "iopub.status.idle": "2023-12-14T13:34:23.393773Z",
     "shell.execute_reply": "2023-12-14T13:34:23.392676Z",
     "shell.execute_reply.started": "2023-12-14T13:34:23.387364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus_id': 1202261, 'score': 0.5694323182106018}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores['cos_sim'][0][0]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4164996,
     "sourceId": 7200583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
